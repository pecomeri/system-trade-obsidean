(1) 破綻点ワークフローの目的（データスヌーピングを抑えつつ、検証を継続的に回す設計）は合理的ですが、現在の構造とドキュメントにはいくつかの潜在的な破綻点が見られます。これらは主にドキュメントの不完全さ、組織化の曖昧さ、検証の厳密さ不足から来ています。

- review_context.mdの不完全さ: 目的、前提、ワークフロー、テーマ、迷っている論点、評価観点がすべてTODOのままで、空のテンプレート状態。これにより、検証の全体像が共有・追跡しにくく、作業者が迷ったり一貫性を失ったりするリスクが高い。結果として、検証がアドホックになり、スヌーピング（後付けの仮説調整）が発生しやすくなる。
- 仮説と結果の散在と重複: tree_fx.txtから、30_hypotheses配下にfamily_A/B/Cなどの仮説群があり、各々にベースライン（e.g., A001, B001）とバリエーション（e.g., A002: 板フィルターあり、A003: H1なし）が存在。これらは差分を1つずつ変える制約を守っているように見えるが、ファミリー間で類似したテスト（e.g., no_h1_filterの繰り返し）が多く、全体として多重テストのリスクが高い。results配下のディレクトリも大量（e.g., b001_2024-01_2024-12_...）で、まとめが不十分（summary_family_BC.csvはあるが、全体統合なし）。これにより、桜の花びら効果（良い結果だけピックアップ）が起きやすく、スヌーピングを抑える目的に反する。
- サンプルノートのドラフト状態とリンクの不備: samples（e.g., S-001_trend_midrange_fakeout_v.md, E-B001_rebreak_confirm.md）はstatus: draftが多く、定義が曖昧（e.g., トレンドの定義が空）。関連リンクはあるが、クロスリファレンスが不完全で、例えばF-C001_no_rebreak.mdの目的が事故抑制と抽象的。実装メモはあるが、コード（backtest_core.pyなど）との紐付けが弱く、検証実行時に再現性やデバッグが崩れやすい。
- 時間軸とデータの制約違反の可能性: 前提として10秒/1分/5分などの時間軸、2024(verify)/2025(forward)が指定されているが、resultsの命名（e.g., 20251216_061228）からバックテストが繰り返されている。制約（数値最適化なし、差分1つずつ）は守られそうだが、family_C_m1entry_v2のようなバージョンアップが複数あり、フォワードテストでの過剰調整の兆候が見られる。データソース（Dukascopy 10秒足、FIX板情報）が明記されているのは良いが、欠損バーやセッション跨ぎの扱いがサンプルで不十分で、実行エラーの原因になる。
- 観測指標とテーマの曖昧さ: 現在のワークフローでB006/B007/B008などの観測指標が挙げられているが、具体的な定義（e.g., h1_uptrend_monthly_ratio_2025.csv）がresultsに散在。検証中の主要テーマ（最大5つ）がTODOのままなので、焦点がぼやけ、検証サイクルが長引くか中断しやすくなる。一番迷っている論点がTODOのため、優先順位付けが崩れる。

これらの破綻点は、全体としてワークフローを「回り続ける」状態から遠ざけ、散漫な検証を招く。(2) 改善提案目的を達成するため、構造化を強化し、スヌーピングを防ぐ仕組みを導入。tree_fx.txtの整理されたディレクトリ構造（00_Index, 10_regimesなど）は強みなので、これを活かす。

- review_context.mdの具体化とバージョン管理: TODOを埋めて定期更新するルールを作り、Gitなどのツールで追跡。目的を「スヌーピング抑制のための事前仮説登録と差分テスト限定」に明確化。前提に「in-sample(2024)/out-of-sample(2025)の厳格分離」を追加し、制約をチェックリスト化（e.g., 差分変更時は理由をノートに記述）。
- 仮説管理の厳密化: 30_hypothesesのようなファミリーを事前登録制にし、多重テスト補正（e.g., Bonferroni修正）を手動で適用。テーマを最大5つに絞り（e.g., 1. H1フィルターの価値, 2. 板フィルターの回避効果, 3. 時間帯フィルターの影響, 4. エントリータイミングの比較, 5. 観測指標の相関）、各仮説にp-valueや期待リターンの閾値を設定。samplesのノートをテンプレート化（e.g., 定義/メリット/リスク/実装を必須項目）し、statusをdraftからactiveへ移行する基準を定義（e.g., 初回バックテスト通過）。
- ワークフロー自動化とまとめ強化: 現在の検証ワークフロー（仮説ノート作成 → runner実行 → results保存 → 観測指標）をスクリプト化（code/backtest_runner.pyを活用）。resultsに自動まとめツールを追加（e.g., Pythonでmonthly.csvを統合し、summary_family_*.csvを標準化）。観測指標をダッシュボード化（e.g., PandasでCSVをプロット）し、迷っている論点を1つに絞るレビューサイクルを週次で実施。
- スヌーピング抑制の追加制約: 差分テストを「A/Bテスト風」に限定（ベースライン vs 1変数変更のみ）。フォワードテスト(2025)を「触らない」ルールにし、resultsのtruncated部分（e.g., 長いCSV）を全文閲覧可能にするツール（e.g., code_executionでPandas読み込み）を導入。外部ベンチマーク（e.g., シンプルMAクロス）と比較して優位性を客観化。
- ドキュメント統合: tree_fx.txtのpreferred/fullビューを活用し、00_Index/全体状況まとめ.mdを中央ハブに。samplesのリンクを双方向にし（e.g., E-B001からS-001へ逆リンク）、99_logsで実行履歴を一元化。

これにより、検証が体系的になり、スヌーピングを抑えつつ継続可能になる。(3) 具体的な次アクション3つ

1. review_context.mdを埋める: 目的を「B002の継続判断とC_v2の進展方向決定」に、前提の時間軸を「10秒執行/1分シグナル/5分構造、verify=2024、forward=2025」に、手法を「バックテスト＋観測指標（B006: H1比率, B007: H1ラン, B008: 状態分類）」、制約を「最適化なし、差分1つずつ」に具体化。主要テーマを「1. 上位足フィルター価値, 2. 時間帯フィルター影響, 3. 板フィルター回避効果, 4. エントリータイミング比較, 5. 観測指標相関」に、迷っている論点を「H1フィルター除去時のフォワード劣化原因」に、評価観点を「1. フォワードPF>1.5, 2. ドローダウン<20%, 3. トレード数安定, 4. フィルター除去時の差分影響, 5. スヌーピング兆候チェック」に設定。完了後、全体状況まとめ.mdに反映。
2. family_B_failedbreakoutの結果をまとめて分析: results/family_B_failedbreakout配下のCSV（e.g., B001_baselineのmonthly.csv, B002_W1_onlyのtrades.csv）をPandasで読み込み、2024(in-sample)と2025(forward)のPF/勝率/平均損益を比較。B006_observationのh1_uptrend_monthly_ratio_2025.csvとmerged_b002_pnl_vs_h1ratio_2025.csvを結合し、H1比率が高い月のパフォーマンス相関を計算。summary.txtに追加し、スヌーピング兆候（e.g., in-sample過剰適合）をチェック。
3. S-001_trend_midrange_fakeout_v.mdをactive化: サンプルノートの定義を埋め（e.g., トレンド: H1 SMA上向き, ミッドレンジ: 5分レンジ中央, フェイクアウト: 10秒偽ブレイク）、関連リンク（E-B001, F-C001）を検証。backtest_runner.pyでhyp001相当を実行し、resultsに保存。statusをdraftからactiveに更新し、破綻点（誤認パターン）をデバッグメモに追加。